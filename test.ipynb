{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Read Input Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "file_image1 = \"image1\"\n",
    "image1 = plt.imread(file_image1 + \".jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Face Detection\n",
    "\n",
    "## Detect"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from source.face_detection import FaceDetector\n",
    "\n",
    "fd = FaceDetector(minimum_confidence=0.95, output_size=250)\n",
    "\n",
    "images_faces = fd.compute([image1]).get_images_faces()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([0.9999987, 0.9999993, 0.9990159], dtype=float32)]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.get_images_faces_scores()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[1479,  829, 1859, 1315],\n        [1983, 1117, 2294, 1497],\n        [2512, 1116, 2791, 1459]], dtype=int16)]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.get_bounding_boxes()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[[1628, 1022],\n         [1792, 1061],\n         [1714, 1149],\n         [1601, 1190],\n         [1741, 1225]],\n \n        [[2084, 1263],\n         [2221, 1268],\n         [2162, 1337],\n         [2096, 1409],\n         [2206, 1416]],\n \n        [[2604, 1259],\n         [2738, 1268],\n         [2676, 1325],\n         [2601, 1378],\n         [2716, 1387]]], dtype=int16)]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.get_facial_keypoints()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for i, faces in enumerate(images_faces):\n",
    "    for j, face in enumerate(faces):\n",
    "        plt.imsave(\n",
    "            f\"{file_image1}_image_index{i}_face_{j}.jpg\",\n",
    "            face\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Face Alignment\n",
    "\n",
    "## Align"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from source.face_alignment import FaceAligner\n",
    "\n",
    "fa = FaceAligner()\n",
    "aligned_images_faces = fa.align_images_faces(images_faces, fd.get_eyes_coordinates())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "for i, image_faces in enumerate(aligned_images_faces):\n",
    "    for j, face in enumerate(image_faces):\n",
    "        plt.imsave(\n",
    "            f\"{file_image1}_rotated_image_index{i}_face_{j}.jpg\",\n",
    "            face\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Face Normalization\n",
    "\n",
    "## Normalize"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, 3, (250, 250, 3))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aligned_images_faces), len(aligned_images_faces[0]), aligned_images_faces[0][0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "from source.face_normalization import FaceNormalizer\n",
    "\n",
    "fn = FaceNormalizer()\n",
    "normalized_aligned_images_faces = fn.normalize_images_faces(aligned_images_faces)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "for i, image_faces in enumerate(normalized_aligned_images_faces):\n",
    "    for j, face in enumerate(image_faces):\n",
    "        plt.imsave(\n",
    "            f\"{file_image1}_normalized_rotated_image_index{i}_face_{j}.jpg\",\n",
    "            face\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Facial Emotion Recognition\n",
    "## Face Emotion Representation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahur4/.hsemotions/enet_b0_8_best_afew.pt Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from source.face_emotion_recognition import FaceEmotionRecognizer\n",
    "\n",
    "model_name = 'enet_b0_8_best_afew'\n",
    "# model_name='enet_b0_8_best_vgaf'\n",
    "# model_name='enet_b0_8_va_mtl'\n",
    "# model_name='enet_b2_8'\n",
    "fer = FaceEmotionRecognizer(model_name, device=\"cuda:0\")\n",
    "images_faces_representations = [fer.extract_representations_from_image_faces(normalized_aligned_image_faces) for normalized_aligned_image_faces in normalized_aligned_images_faces\n",
    "                                ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[-0.0864, -0.0695,  0.3409,  ..., -0.0926,  0.0393,  0.0659],\n         [ 0.1862, -0.1005,  0.3144,  ...,  0.1115, -0.1877,  0.0243],\n         [ 0.0773,  0.0140,  0.5271,  ..., -0.0428,  0.1012, -0.1217]],\n        device='cuda:0', grad_fn=<ReshapeAliasBackward0>)]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_faces_representations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(1, torch.Size([3, 1280]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 image, 3 face in this image, each face representation is vector of (1, 1280) shape\n",
    "len(images_faces_representations), images_faces_representations[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Face Emotion Recognition"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "images_faces_predictions_labels_scores = [fer.predict_emotions_from_image_faces_representations(image_faces_representations) for image_faces_representations in images_faces_representations]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[(['Happiness', 'Anger', 'Fear'],\n  tensor([[-2.3273,  0.8328, -0.6988,  0.6483,  3.2102,  1.4981, -0.0774, -0.3872],\n          [ 5.6108, -0.5087,  0.4402,  1.7418, -2.9160,  1.7116,  2.6144, -1.6169],\n          [-2.3844, -2.7352,  0.3890,  2.6326,  0.9862, -0.6138,  1.8679, -0.2901]],\n         device='cuda:0', grad_fn=<AddBackward0>))]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_faces_predictions_labels_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Representation Extraction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from source.representation_extraction import EmotionRepresentationExtractor\n",
    "from source.face_detection import FaceDetector\n",
    "from source.face_alignment import FaceAligner\n",
    "from source.face_normalization import FaceNormalizer\n",
    "from source.face_emotion_recognition import FaceEmotionRecognizer\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Read Images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file_image1 = \"image1\"\n",
    "image1 = plt.imread(file_image1 + \".jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ahur4/.hsemotions/enet_b0_8_best_afew.pt Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fd = FaceDetector(minimum_confidence=0.95, output_size=250)\n",
    "fa = FaceAligner()\n",
    "fn = FaceNormalizer()\n",
    "model_name = 'enet_b0_8_best_afew'\n",
    "# model_name='enet_b0_8_best_vgaf'\n",
    "# model_name='enet_b0_8_va_mtl'\n",
    "# model_name='enet_b2_8'\n",
    "fer = FaceEmotionRecognizer(model_name, device=\"cuda:0\")\n",
    "\n",
    "fre = EmotionRepresentationExtractor().set_face_detection_model(fd, ).set_face_alignment_model(fa, ).set_face_normalizer_model(fn).set_face_emotion_recognition_model(fer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[-0.0864, -0.0695,  0.3409,  ..., -0.0926,  0.0393,  0.0659],\n         [ 0.1862, -0.1005,  0.3144,  ...,  0.1115, -0.1877,  0.0243],\n         [ 0.0773,  0.0140,  0.5271,  ..., -0.0428,  0.1012, -0.1217]],\n        device='cuda:0', grad_fn=<ReshapeAliasBackward0>)]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_faces_representations = fre.extract_representation([image1])\n",
    "images_faces_representations # Next Step: Mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}